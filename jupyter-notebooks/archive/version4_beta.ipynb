{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c8089b-559e-4a27-9a3c-f06713780d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import torchvision\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import timm\n",
    "\n",
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "from adamp import AdamP\n",
    "from adamp import SGDP\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "172497aa-b7f7-45a6-b912-4487d04c21de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "004_loss_0.017.ckpt  8.30_1  8.30_3\t       version3.ipynb  vgg19\n",
      "8.29\t\t     8.30_2  requirements.txt  version4.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c756ad1-dddd-4277-abbb-8552140c8e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/ml/input/data'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TAR_PATH = '/opt/ml/input/data/train'\n",
    "PARENT_DATA_PATH = '/opt/ml/input'\n",
    "DATA_PATH = os.path.join(PARENT_DATA_PATH, \"data\")\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "769283a5-a6b6-4ef1-b6b4-9cb052a0e160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700 ['/opt/ml/input/data/train/images/000009_female_Asian_56', '/opt/ml/input/data/train/images/000574_female_Asian_56', '/opt/ml/input/data/train/images/000041_female_Asian_58', '/opt/ml/input/data/train/images/004488_male_Asian_23', '/opt/ml/input/data/train/images/003880_female_Asian_55', '/opt/ml/input/data/train/images/001617_female_Asian_37', '/opt/ml/input/data/train/images/001047_male_Asian_60', '/opt/ml/input/data/train/images/003567_female_Asian_25', '/opt/ml/input/data/train/images/001308_male_Asian_26', '/opt/ml/input/data/train/images/001751_male_Asian_51']\n"
     ]
    }
   ],
   "source": [
    "TRAIN_IMGS_DATASET_PATH = \"/opt/ml/input/data/train/images\"\n",
    "EVAL_IMGS_DATASET_PATH = \"/opt/ml/input/data/eval/images\"\n",
    "\n",
    "list_individuals = glob.glob(os.path.join(TRAIN_IMGS_DATASET_PATH, \"*\"))\n",
    "print(len(list_individuals) ,list_individuals[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aacc84d2-5d33-4722-8e52-91734ab1e346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2700"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(TRAIN_IMGS_DATASET_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59e5819d-546b-49c0-8f4a-5fa617e5a284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n"
     ]
    }
   ],
   "source": [
    "superflous_folders = glob.glob(os.path.join(TRAIN_IMGS_DATASET_PATH,\"._*\"))\n",
    "print(len(superflous_folders),superflous_folders[:10])\n",
    "for item in superflous_folders:\n",
    "  os.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd7bf250-7a05-43c3-9c03-5802502ceb22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mask4.jpg',\n",
       " 'mask1.jpg',\n",
       " 'incorrect_mask.jpg',\n",
       " 'mask3.jpg',\n",
       " 'mask5.jpg',\n",
       " 'normal.jpg',\n",
       " 'mask2.jpg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personal_id = \"001771_female_Asian_54\"\n",
    "os.listdir(os.path.join(TRAIN_IMGS_DATASET_PATH, personal_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0032ffb8-7c36-4fcd-bb0f-699f217611cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mask4.jpg',\n",
       " 'mask1.jpg',\n",
       " 'incorrect_mask.jpg',\n",
       " 'mask3.jpg',\n",
       " 'mask5.jpg',\n",
       " 'normal.jpg',\n",
       " 'mask2.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_folders = glob.glob(os.path.join(TRAIN_IMGS_DATASET_PATH,\"*\"))\n",
    "for folder in list_folders:\n",
    "  superflous_files = glob.glob(os.path.join(folder,\"._*\"))\n",
    "  for file in superflous_files:\n",
    "    os.remove(file)\n",
    "    \n",
    "personal_id = \"001771_female_Asian_54\"\n",
    "os.listdir(os.path.join(TRAIN_IMGS_DATASET_PATH, personal_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7ade470-4210-4968-ad2d-2af8c449dc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process cleared, untarred properly\n"
     ]
    }
   ],
   "source": [
    "for individual_name in list_individuals:\n",
    "  individual_path = os.path.join(TRAIN_IMGS_DATASET_PATH, individual_name)\n",
    "  \n",
    "  # check whether dataset is properly untarred\n",
    "  jpg_file_list = glob.glob(f\"{individual_path}/*.jpg\")\n",
    "  jpeg_file_list = glob.glob(f\"{individual_path}/*.jpeg\")\n",
    "  png_file_list = glob.glob(f\"{individual_path}/*.png\")\n",
    "  list_images = jpg_file_list + jpeg_file_list + png_file_list\n",
    "  num_jpg_images = len(list_images)\n",
    "  # print(num_jpg_images)\n",
    "  if num_jpg_images == 7:\n",
    "    pass\n",
    "  else:\n",
    "    print(f\"{individual_path} has a problem during untar process, only has {num_jpg_images} images\")\n",
    "    pass\n",
    "print(\"process cleared, untarred properly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38986e73-a226-4a28-8f0a-e95f952a300a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: adamp in /opt/conda/lib/python3.8/site-packages (0.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install adamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01a40078-4681-4e78-8436-2bd722978274",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /opt/conda/lib/python3.8/site-packages (0.4.12)\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.8/site-packages (from timm) (1.7.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from timm) (0.8.2)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.4->timm) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torch>=1.4->timm) (1.19.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.8/site-packages (from torchvision->timm) (8.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db8f2a18-769f-4f32-b26f-d3c3813701f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t_transform = Compose([\n",
    "    #Resize(img_size[0], img_size[1], p=1.0),\n",
    "    #Resize(200, 260, p=1.0),\n",
    "    CenterCrop(height = 400, width = 250), # add centercrop 350/350 -> 400/200 -> 300/300\n",
    "    #HorizontalFlip(p=0.5),\n",
    "    #ShiftScaleRotate(p=0.5),\n",
    "    #HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "    RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "    #GaussNoise(p=0.5),\n",
    "    Normalize(mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246), max_pixel_value=255.0, p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "    ], p=1.0)\n",
    "\n",
    "\n",
    "v_transform = Compose([\n",
    "    #Resize(img_size[0], img_size[1]),\n",
    "    #Resize(200, 260),\n",
    "    CenterCrop(height = 400, width = 250), # add centercrop\n",
    "    Normalize(mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246), max_pixel_value=255.0, p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "    ], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af61663d-c3c7-4109-a5dd-62e3750ac074",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskLabels:\n",
    "    mask = 0\n",
    "    incorrect = 1\n",
    "    normal = 2\n",
    "\n",
    "class GenderLabels:\n",
    "    male = 0\n",
    "    female = 1\n",
    "\n",
    "class AgeGroup:\n",
    "    map_label = lambda x: 0 if int(x) < 30 else 1 if int(x) < 58 else 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f69b3516-1c80-44e6-a253-676dc46ece8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskBaseDataset(data.Dataset):\n",
    "    num_classes = 3 * 2 * 3\n",
    "\n",
    "    _file_names = {\n",
    "        \"mask1.jpg\": MaskLabels.mask,\n",
    "        \"mask2.jpg\": MaskLabels.mask,\n",
    "        \"mask3.jpg\": MaskLabels.mask,\n",
    "        \"mask4.jpg\": MaskLabels.mask,\n",
    "        \"mask5.jpg\": MaskLabels.mask,\n",
    "        \"incorrect_mask.jpg\": MaskLabels.incorrect,\n",
    "        \"normal.jpg\": MaskLabels.normal,\n",
    "        \n",
    "        \"mask1.jpeg\": MaskLabels.mask,\n",
    "        \"mask2.jpeg\": MaskLabels.mask,\n",
    "        \"mask3.jpeg\": MaskLabels.mask,\n",
    "        \"mask4.jpeg\": MaskLabels.mask,\n",
    "        \"mask5.jpeg\": MaskLabels.mask,\n",
    "        \"incorrect_mask.jpeg\": MaskLabels.incorrect,\n",
    "        \"normal.jpeg\": MaskLabels.normal,\n",
    "        \n",
    "        \"mask1.png\": MaskLabels.mask,\n",
    "        \"mask2.png\": MaskLabels.mask,\n",
    "        \"mask3.png\": MaskLabels.mask,\n",
    "        \"mask4.png\": MaskLabels.mask,\n",
    "        \"mask5.png\": MaskLabels.mask,\n",
    "        \"incorrect_mask.png\": MaskLabels.incorrect,\n",
    "        \"normal.png\": MaskLabels.normal\n",
    "    }\n",
    "\n",
    "    image_paths = []\n",
    "    mask_labels = []\n",
    "    gender_labels = []\n",
    "    age_labels = []\n",
    "\n",
    "    def __init__(self, img_dir, mean, std, transform=None):\n",
    "        \"\"\"\n",
    "        MaskBaseDataset을 initialize 합니다.\n",
    "\n",
    "        Args:\n",
    "            img_dir: 학습 이미지 폴더의 root directory 입니다.\n",
    "            transform: Augmentation을 하는 함수입니다.\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.transform = transform\n",
    "\n",
    "        self.setup()\n",
    "\n",
    "    def set_transform(self, transform):\n",
    "        \"\"\"\n",
    "        transform 함수를 설정하는 함수입니다.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        \n",
    "    def setup(self):\n",
    "        \"\"\"\n",
    "        image의 경로와 각 이미지들의 label을 계산하여 저장해두는 함수입니다.\n",
    "        \"\"\"\n",
    "        profiles = os.listdir(self.img_dir)\n",
    "        for profile in profiles:\n",
    "            for file_name, label in self._file_names.items():\n",
    "                img_path = os.path.join(self.img_dir, profile, file_name)  # (resized_data, 000004_male_Asian_54, mask1.jpg)\n",
    "                if os.path.exists(img_path):\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.mask_labels.append(label)\n",
    "\n",
    "                    id, gender, race, age = profile.split(\"_\")\n",
    "                    gender_label = getattr(GenderLabels, gender)\n",
    "                    age_label = AgeGroup.map_label(age)\n",
    "\n",
    "                    self.gender_labels.append(gender_label)\n",
    "                    self.age_labels.append(age_label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        데이터를 불러오는 함수입니다. \n",
    "        데이터셋 class에 데이터 정보가 저장되어 있고, index를 통해 해당 위치에 있는 데이터 정보를 불러옵니다.\n",
    "        \n",
    "        Args:\n",
    "            index: 불러올 데이터의 인덱스값입니다.\n",
    "        \"\"\"\n",
    "        # 이미지를 불러옵니다.\n",
    "        image_path = self.image_paths[index]\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # 레이블을 불러옵니다.\n",
    "        mask_label = self.mask_labels[index]\n",
    "        gender_label = self.gender_labels[index]\n",
    "        age_label = self.age_labels[index]\n",
    "        multi_class_label = mask_label * 6 + gender_label * 3 + age_label\n",
    "        \n",
    "        # 이미지를 Augmentation 시킵니다.\n",
    "        image_transform = self.transform(image=np.array(image))['image']\n",
    "        return image_transform, multi_class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9d56ec1-ab1b-4de5-85eb-321aace74e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None,\n",
    "                 gamma=2., reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1 - prob) ** self.gamma) * log_prob,\n",
    "            target_tensor,\n",
    "            weight=self.weight,\n",
    "            reduction=self.reduction\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1221c0ef-28bd-4292-8ddc-d5052cef071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes=3, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "380229e0-34ad-475d-867f-fbfc76c492be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Loss(nn.Module):\n",
    "    def __init__(self, classes=3, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.classes = classes\n",
    "        self.epsilon = epsilon\n",
    "    def forward(self, y_pred, y_true):\n",
    "        assert y_pred.ndim == 2\n",
    "        assert y_true.ndim == 1\n",
    "        y_true = F.one_hot(y_true, self.classes).to(torch.float32)\n",
    "        y_pred = F.softmax(y_pred, dim=1)\n",
    "\n",
    "        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n",
    "        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n",
    "        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "\n",
    "        precision = tp / (tp + fp + self.epsilon)\n",
    "        recall = tp / (tp + fn + self.epsilon)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + self.epsilon)\n",
    "        f1 = f1.clamp(min=self.epsilon, max=1 - self.epsilon)\n",
    "        return 1 - f1.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8466ebec-8dcc-415f-adfa-031868be116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_criterion_entrypoints = {\n",
    "    'cross_entropy': nn.CrossEntropyLoss,\n",
    "    'focal': FocalLoss,\n",
    "    'label_smoothing': LabelSmoothingLoss,\n",
    "    'f1': F1Loss\n",
    "}\n",
    "\n",
    "def criterion_entrypoint(criterion_name):\n",
    "    return _criterion_entrypoints[criterion_name]\n",
    "\n",
    "\n",
    "def is_criterion(criterion_name):\n",
    "    return criterion_name in _criterion_entrypoints\n",
    "\n",
    "\n",
    "def create_criterion(criterion_name, **kwargs):\n",
    "    if is_criterion(criterion_name):\n",
    "        create_fn = criterion_entrypoint(criterion_name)\n",
    "        criterion = create_fn(**kwargs)\n",
    "    else:\n",
    "        raise RuntimeError('Unknown loss (%s)' % criterion_name)\n",
    "    return criterion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d31276f-f0fb-49d0-838e-92a30c1c771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_loss(y_true:torch.Tensor, y_pred:torch.Tensor, is_training=False) -> torch.Tensor:\n",
    "    \n",
    "    assert y_true.ndim == 1\n",
    "    assert y_pred.ndim == 1 or y_pred.ndim == 2\n",
    "    \n",
    "    if y_pred.ndim == 2:\n",
    "        y_pred = y_pred.argmax(dim=1)\n",
    "        \n",
    "    \n",
    "    tp = (y_true * y_pred).sum().to(torch.float32)\n",
    "    tn = ((1 - y_true) * (1 - y_pred)).sum().to(torch.float32)\n",
    "    fp = ((1 - y_true) * y_pred).sum().to(torch.float32)\n",
    "    fn = (y_true * (1 - y_pred)).sum().to(torch.float32)\n",
    "    \n",
    "    epsilon = 1e-7\n",
    "    \n",
    "    precision = tp / (tp + fp + epsilon)\n",
    "    recall = tp / (tp + fn + epsilon)\n",
    "    \n",
    "    f1 = 2* (precision*recall) / (precision + recall + epsilon)\n",
    "    f1.requires_grad = is_training\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b84e329-fb47-403e-91f7-42fc2512701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_Mean = [0.56019358, 0.52410121, 0.501457]\n",
    "RGB_SD = [0.23318603, 0.24300033, 0.24567522]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a985a5ab-8e19-4b66-a809-8f9271e688a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/opt/ml/input/data/train'\n",
    "IMG_DIR = f'{BASE_DIR}/images'\n",
    "TRAIN_CSV = f'{BASE_DIR}/train.csv'\n",
    "SPLIT_RATIO = 0.2\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VAL_BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63c89e7f-14e0-4720-8be8-ab6914c8f1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.Subset object at 0x7fa6d46c6e20>\n",
      "<torch.utils.data.dataset.Subset object at 0x7fa6d46c21f0>\n"
     ]
    }
   ],
   "source": [
    "#transform_t = get_train_transforms(mean=RGB_Mean, std=RGB_SD)\n",
    "#transform_v = get_val_transforms(mean=RGB_Mean, std=RGB_SD)\n",
    "dataset = MaskBaseDataset(\n",
    "    img_dir=IMG_DIR,\n",
    "    mean = RGB_Mean,\n",
    "    std = RGB_SD\n",
    ")\n",
    "\n",
    "# train dataset과 validation dataset을 9:1 비율로 나눕니다.\n",
    "n_val = int(len(dataset) * SPLIT_RATIO)\n",
    "n_train = len(dataset) - n_val\n",
    "train_dataset, val_dataset = data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "# 각 dataset에 augmentation 함수를 설정합니다.\n",
    "train_dataset.dataset.set_transform(t_transform)\n",
    "val_dataset.dataset.set_transform(v_transform)\n",
    "print(train_dataset)\n",
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c09aa20-4e27-4ee1-bcad-0600371d6d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = CutMix(train_dataset, num_class=1000, beta=1.0, prob=0.5, num_mix=2)\n",
    "#val_dataset = CutMix(val_dataset, num_class=1000, beta=1.0, prob=0.5, num_mix=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86f6e386-31a8-4781-bdb4-3a2772571c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_loader = data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    num_workers=2,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb95fb76-4de2-4e14-8b39-5034285b521b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images shape: torch.Size([32, 3, 400, 250])\n",
      "labels shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "print(f'images shape: {images.shape}')\n",
    "print(f'labels shape: {labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1306a24a-04cc-46e1-905b-658c2a5b231b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "GPU Name: Tesla V100-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('GPU Name:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU, using CPU.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd0ba0a0-b249-4906-92f9-6459d13f09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ba58ae7-e0e4-49b5-9ab6-f497f88a1104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes: int = 18):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Transfer learning to add final layers in the end.\n",
    "        # Model Comaprison: https://paperswithcode.com/sota/image-classification-on-imagenet\n",
    "        # self.backbone = models.resnet50(pretrained=True)\n",
    "        # self.backbone = models.resnext50_32x4d(pretrained=True)\n",
    "        \n",
    "        model_architecture = 'tf_efficientnet_b4'\n",
    "        self.backbone = timm.create_model(model_architecture, pretrained=True)\n",
    "        n_features = self.backbone.classifier.in_features\n",
    "        print(n_features)\n",
    "        self.backbone.fc = nn.Linear(in_features=n_features, out_features=num_classes, bias=True)\n",
    "        #self.backbone.fc = nn.Linear(in_features=2048, out_features=18, bias=True)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74839c3e-a2ad-4ca8-be40-14c687a678ce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (backbone): EfficientNet(\n",
       "    (conv_stem): Conv2dSame(3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): SiLU(inplace=True)\n",
       "    (blocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): DepthwiseSeparableConv(\n",
       "          (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "          (bn1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Identity()\n",
       "        )\n",
       "        (1): DepthwiseSeparableConv(\n",
       "          (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "          (bn1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2dSame(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
       "          (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2dSame(192, 192, kernel_size=(5, 5), stride=(2, 2), groups=192, bias=False)\n",
       "          (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "          (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "          (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "          (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(56, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2dSame(336, 336, kernel_size=(3, 3), stride=(2, 2), groups=336, bias=False)\n",
       "          (bn2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "          (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "          (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "          (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "          (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (5): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "          (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (5): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2dSame(960, 960, kernel_size=(5, 5), stride=(2, 2), groups=960, bias=False)\n",
       "          (bn2): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "          (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "          (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "          (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "          (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (5): InvertedResidual(\n",
       "          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "          (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (6): InvertedResidual(\n",
       "          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "          (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (7): InvertedResidual(\n",
       "          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "          (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(272, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1632, 1632, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1632, bias=False)\n",
       "          (bn2): BatchNorm2d(1632, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(2688, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(2688, 2688, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2688, bias=False)\n",
       "          (bn2): BatchNorm2d(2688, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(2688, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(112, 2688, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(1792, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act2): SiLU(inplace=True)\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (classifier): Linear(in_features=1792, out_features=1000, bias=True)\n",
       "    (fc): Linear(in_features=1792, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2eeb01a9-16be-4f37-b426-61fa5088d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adamp import AdamP\n",
    "\n",
    "\n",
    "# # Freeze the feature extracting convolution layers\n",
    "# for param in model.features.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "criterion = FocalLoss(gamma = 5)\n",
    "#criterion = CutMixCrossEntropyLoss(True)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "optimizer = AdamP(model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999), weight_decay= WEIGHT_DECAY)\n",
    "#optimizer = SGDP(model.parameters(), lr=LEARNING_RATE, weight_decay= WEIGHT_DECAY,momentum=0.9, nesterov=True)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[500,1000,1500], gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2fa660f-bdf3-41d6-9e8e-ccd3ee294d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8281594-06e9-4135-b19d-3afe394b8391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train(model, epochs, train_loader, valid_loader, save_path):\n",
    "    best_valid_acc = 0\n",
    "    best_valid_loss = 100000\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_train_loss, epoch_train_acc = Metrics(), Metrics()\n",
    "        early_stop = 0\n",
    "        for iter, (img,label) in enumerate(tqdm(train_loader)):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            img, label = img.type(torch.FloatTensor).to(device), label.to(device)\n",
    "\n",
    "            # 모델에 이미지 forward\n",
    "            model.train()\n",
    "            pred_logit = model(img)\n",
    "\n",
    "            # loss 값 계산\n",
    "            loss = criterion(pred_logit,label)\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Accuracy 계산\n",
    "            pred_label = torch.max(pred_logit.data,1)\n",
    "\n",
    "            # pred_label  = pred_logit.argmax(1)\n",
    "            acc = (pred_label.indices == label).sum().item() / len(label)\n",
    "\n",
    "            epoch_train_loss.update(loss.item(), len(img))\n",
    "            epoch_train_acc.update(acc, len(img))\n",
    "\n",
    "            train_loss = loss.item()\n",
    "            train_acc = acc\n",
    "            \n",
    "#             if (iter % 300 == 0) or (iter == len(train_loader)-1):\n",
    "#                 print(\"Iter [%3d/%3d] | Train Loss %.4f | Train Acc %.4f\" %(iter, len(train_loader), train_loss, train_acc))\n",
    "\n",
    "        epoch_train_loss = epoch_train_loss.avg\n",
    "        epoch_train_acc = epoch_train_acc.avg\n",
    "        print(\"Epoch %d | Train Loss %.4f | Train Acc %.4f\"%(epoch,epoch_train_loss, epoch_train_acc))\n",
    "        \n",
    "        valid_loss, valid_acc, valid_f1 = Metrics(), Metrics(), Metrics()\n",
    "        model.eval()\n",
    "        \n",
    "        for img, label in valid_loader:\n",
    "            img, label = img.type(torch.FloatTensor).to(device), label.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred_logit = model(img)\n",
    "            loss = criterion(pred_logit, label) \n",
    "            pred_label = torch.max(pred_logit.data,1)\n",
    "\n",
    "            acc = (pred_label.indices == label).sum().item() / len(label)\n",
    "\n",
    "            valid_loss.update(loss.item(), len(img))\n",
    "            valid_acc.update(acc, len(img))\n",
    "            valid_f1.update(f1_loss(label, pred_label.indices), len(img))\n",
    "\n",
    "\n",
    "        valid_loss = valid_loss.avg\n",
    "        valid_acc = valid_acc.avg\n",
    "        valid_f1 = valid_f1.avg\n",
    "        print(\"Valid Loss %.4f | Valid Acc %.4f | f1 score %.4f\" %(valid_loss, valid_acc, valid_f1))\n",
    "        \n",
    "        if valid_loss <= best_valid_loss:\n",
    "            print(\"New valid model for val loss! saving the model...\")\n",
    "            torch.save(model.state_dict(),PATH + f\"{epoch:03}_loss_{valid_loss:4.2}.ckpt\")\n",
    "            best_valid_loss = valid_loss\n",
    "            early_stop = 0\n",
    "        else:\n",
    "            early_stop += 1\n",
    "            if early_stop > 2:\n",
    "                break\n",
    "        \n",
    "        if valid_acc > best_valid_acc:\n",
    "            print(\"New valid model for val accuracy! saving the model...\")\n",
    "            torch.save(model.state_dict(),PATH + f\"{epoch:03}_loss_{valid_loss:4.2}.ckpt\")\n",
    "            best_valid_acc = valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55c91e66-4498-49ac-849a-e083ca91de49",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb699d67d5de47a1b49c28f80ea7d8ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 | Train Loss 0.2437 | Train Acc 0.7788\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-87a3919f4392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# (Train Image Size = 1890 * 9) / (Batch Size = 32) = 532 as Length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-1aa05aad6aa7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epochs, train_loader, valid_loader, save_path)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mpred_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_logit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mvalid_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PATH = \"./\"\n",
    "\n",
    "# (Train Image Size = 1890 * 9) / (Batch Size = 32) = 532 as Length\n",
    "train(model, EPOCHS, train_loader, valid_loader, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214fe5c8-5a3b-43a2-939b-cf8c6fe5b7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a0af1e-3440-4cdc-9886-e1f61eaac2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(data.Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.img_paths[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf917dd-cbb0-4c22-b326-2cb21139ae0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"/opt/ml/code/004_loss_0.017.ckpt\"\n",
    "model = MyModel()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc814aa-64e9-4c6c-abf5-79e5f81fe7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL_NAME = \"eff_b4_v4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9724afc2-51fb-47eb-b53d-3078635ca3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ttach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aafda0a-9eaf-434b-9590-bcb6cd11d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "import ttach as tta\n",
    "TEST_DIR = \"/opt/ml/input/data/eval\"\n",
    "\n",
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(TEST_DIR, 'info.csv'))\n",
    "image_dir = os.path.join(TEST_DIR, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    transforms.CenterCrop((400,200)),\n",
    "    ToTensor(),\n",
    "    transforms.Normalize((0.56019358, 0.52410121, 0.501457), (0.23318603, 0.24300033, 0.24567522)),\n",
    "])\n",
    "'''\n",
    "valid_transform = tta.Compose([\n",
    "    #Resize((512, 384), Image.BILINEAR),\n",
    "    #tta.CenterCrop(400,200),\n",
    "    #tta.ToTensor(),\n",
    "    #tta.Normalize((0.56019358, 0.52410121, 0.501457), (0.23318603, 0.24300033, 0.24567522)),\n",
    "    tta.HorizontalFlip(),\n",
    "    tta.Rotate90(angles=[0, 180]),\n",
    "    tta.Scale(scales=[1, 2, 4]),\n",
    "    tta.Multiply(factors=[0.9, 1, 1.1]),    \n",
    "])\n",
    "'''\n",
    "dataset = TestDataset(image_paths, valid_transform)\n",
    "\n",
    "loader = data.DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "pred_result = []\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images, path in tqdm(loader):\n",
    "    temp = []\n",
    "    temp.append(path)\n",
    "    with torch.no_grad():\n",
    "        images = images.type(torch.FloatTensor).to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        temp.append(pred)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "    pred_result.append(temp)\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "file_name = f\"{PRETRAINED_MODEL_NAME}_submission.csv\"\n",
    "submission.to_csv(os.path.join(TEST_DIR, file_name), index=False)\n",
    "print('test inference is done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
