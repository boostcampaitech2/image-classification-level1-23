{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"colab":{"name":"4_Model.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"UmDju1hmS-__"},"source":["## Lesson 5 - Model\n"," - 이번 실습 자료에서는 강의시간에 다루었던 파이토치 모델을 정의하는 방법에 대해 실습하겠습니다.\n"," - 파이토치 모델은 기본적으로 `nn.Module` 클래스를 상속하여 사용합니다.\n","     - [공식문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)에 따르면 `nn.Module` 은 다음과 같은 기능을 합니다\n","     ```\n","     Base class for all neural network modules.\n","     Your models should also subclass this class.\n","     Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes:\n","     ```"],"id":"UmDju1hmS-__"},{"cell_type":"code","metadata":{"id":"zCROkRzlS-_7"},"source":["from pprint import pprint\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"id":"zCROkRzlS-_7","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"toANDtC5S_AA"},"source":["class Model(nn.Module):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, bias=True)\n","        self.bn1 = nn.BatchNorm2d(num_features=3)\n","        self.conv2 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3, bias=False)\n","\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        return F.relu(self.conv2(x))"],"id":"toANDtC5S_AA","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uWxGW2iyS_AB"},"source":["model = Model()\n","model"],"id":"uWxGW2iyS_AB","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NtmySw1gS_AC"},"source":["### 모델 디버깅\n"," - 파이토치 모델들은 다음과 같읕 방법들을 통해 파라미터를 눈으로 확인할 수 있습니다."],"id":"NtmySw1gS_AC"},{"cell_type":"code","metadata":{"scrolled":true,"id":"sX8A26RhS_AD"},"source":["# 1. named_parameters() 를 이용하는 방식\n","for param, weight in model.named_parameters():\n","    print(f\"{param:20} - size: {weight.size()}\")\n","    print(weight)\n","    print(\"-\" * 100)\n","    print()"],"id":"sX8A26RhS_AD","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RGOd8u6NS_AD"},"source":["# 2. 멤버 변수를 이용하여 직접 access 하는 방법\n","print(model.conv1.weight)\n","print(model.conv1.bias)"],"id":"RGOd8u6NS_AD","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PV5CYMXRS_AE"},"source":["### 학습된 모델 저장하기\n"," - `torch.save(model.state_dict(), save_path)`"],"id":"PV5CYMXRS_AE"},{"cell_type":"code","metadata":{"id":"Cq8GYbN1S_AF"},"source":["import os\n","\n","save_folder = \"./runs/\"\n","save_path = os.path.join(save_folder, \"best.pth\")   # ./runs/best.pth\n","os.makedirs(save_folder, exist_ok=True)  \n","\n","torch.save(model.state_dict(), save_path)\n","print(f\"{save_path} 폴더에 모델이 성공적으로 저장되었습니다.\")\n","print(f\"해당 폴더의 파일 리스트: {os.listdir(save_folder)}\")"],"id":"Cq8GYbN1S_AF","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BqwVdTsKS_AF"},"source":["### 저장된 모델 불러오기\n"," - model.load_state_dict(torch.load(save_path))"],"id":"BqwVdTsKS_AF"},{"cell_type":"code","metadata":{"id":"bZ4UN19tS_AG"},"source":["new_model = Model()\n","new_model.load_state_dict(torch.load(save_path))\n","print(f\"{save_path} 에서 성공적으로 모델을 load 하였습니다.\")"],"id":"bZ4UN19tS_AG","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WZn5x9SdS_AG"},"source":["#### 저장된 모델이 잘 불러와졌는지 확인해봅시다"],"id":"WZn5x9SdS_AG"},{"cell_type":"code","metadata":{"id":"qRYRythjS_AH"},"source":["for (name, trained_weight), (_, saved_weight) in zip(model.named_parameters(), new_model.named_parameters()):\n","    is_equal = torch.equal(trained_weight, saved_weight)\n","    print(f\"파라미터 {name:15} 에 대하여 trained 모델과 load 된 모델의 값이 같나요? -> {is_equal}\")"],"id":"qRYRythjS_AH","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z9JD_kYqS_AH"},"source":["#### state_dict() 이 무엇인가요?\n"," - 모델의 저장과 로딩에 `state_dict()` 을 사용하는데, 기능이 무엇인가요?\n"," - 기본적으로 위에서 살펴본 `.named_parameters()` 와 매우 유사합니다\n"," - model parameter 를 Key 로 가지고, model weights 를 Value 로 가지는 파이썬 딕셔너리일 뿐입니다. \n","   (정확한 Type 은 파이썬 내장 라이브러리 collections.OrderDict 입니다)"],"id":"z9JD_kYqS_AH"},{"cell_type":"code","metadata":{"scrolled":false,"id":"0yKFEBJTS_AH"},"source":["for param, weight in model.state_dict().items():\n","    print(f\"파라미터 네임 {param:25} / 사이즈: {weight.size()}\")\n","    print(weight)\n","    print(\"-\" * 100, end=\"\\n\\n\")"],"id":"0yKFEBJTS_AH","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ed5j0w3rS_AI"},"source":["from collections import OrderedDict\n","print(f\"model.state_dict() 의 Type : {type(model.state_dict())}\")\n","isinstance(model.state_dict(), OrderedDict)"],"id":"Ed5j0w3rS_AI","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aoJVB7XUS_AI"},"source":["#### `named_parameters()` 을 안쓰고 `state_dict()` 을 사용하는 이유가 무언인가요? (둘이 뭐가 다른가요)\n"," - `named_parameters()` : returns only parameters\n"," - `state_dict()`: returns both parameters and buffers (e.g. BN runnin_mean, running_var)\n"," \n"," [Reference](https://stackoverflow.com/a/54747245)"],"id":"aoJVB7XUS_AI"},{"cell_type":"code","metadata":{"id":"rKBfbJJYS_AJ"},"source":["pprint([name for (name, param) in model.named_parameters()])  # named_parameters() : returns only parameters\n","print()\n","pprint(list(model.state_dict().keys()))                       # state_dict(): retuns both parameters and buffers"],"id":"rKBfbJJYS_AJ","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vZBCDWBfS_AJ"},"source":["### CPU vs GPU\n"," - Pytorch 텐서(데이터)는 다양한 프로세서(CPU, GPU, TPU) 에서 연산 및 학습이 가능합니다.\n"," - 따라서, 특정 프로세서에서 학습을 진행하고 싶은 경우 해당 프로세스를 명시적으로 지정해주어야 합니다.\n"," - 이는 해당 텐서(데이터)를 특정 프로세스의 메모리에 load 또는 해당 프로세스의 메모리로 이동하는 것을 의미합니다.\n"," - 따라서, 연산하는 텐서들의 디바이스가 같아야만 연산이 가능합니다. 그렇지 않을 경우 에러가 발생합니다."],"id":"vZBCDWBfS_AJ"},{"cell_type":"markdown","metadata":{"id":"mmCL_sXES_AK"},"source":["#### 새로운 텐서 생성"],"id":"mmCL_sXES_AK"},{"cell_type":"code","metadata":{"id":"I_EH9jgOS_AK"},"source":["data = torch.randn(2,2, device=torch.device('cpu'))     # CPU 에 새로운 텐서 생성\n","print(f\"데이터 디바이스: {data.device}\")\n","\n","data = torch.randn(2,2, device=torch.device('cuda:0'))  # GPU 0번에 새로운 텐서 생성\n","print(f\"데이터 디바이스: {data.device}\")\n","\n","data = torch.randn(2,2)                                 # device 를 따로 지정하지 않으면 default 로 CPU 에 생성됩니다.\n","print(f\"데이터 디바이스: {data.device}\")"],"id":"I_EH9jgOS_AK","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FcA2NEVmS_AK"},"source":["#### 이미 생성되어 있는 텐서를 다른 프로세스의 메모리로 이동하는 것도 가능합니다\n","#### .cpu()\n","모든 모델의 파라미터와 버터를 CPU 메모리로 이동"],"id":"FcA2NEVmS_AK"},{"cell_type":"code","metadata":{"id":"c8R3ygRRS_AL"},"source":["model.cpu()\n","for weight in model.parameters():\n","    print(f\"파라미터 디바이스: {weight.device}\")"],"id":"c8R3ygRRS_AL","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GobjlWa6S_AL"},"source":["#### .cuda()\n","모든 모델의 파라미터와 버터를 GPU 메모리로 이동"],"id":"GobjlWa6S_AL"},{"cell_type":"code","metadata":{"id":"Knj_icpAS_AL"},"source":["model.cuda()\n","for weight in model.parameters():\n","    print(f\"파라미터 디바이스: {weight.device}\")"],"id":"Knj_icpAS_AL","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qwOb6ccTS_AM"},"source":["#### .to()\n","파라미터 또는 버퍼 메모리를 다음 프로세스로 이동"],"id":"qwOb6ccTS_AM"},{"cell_type":"code","metadata":{"id":"pEOar6EWS_AM"},"source":["device_options = ['cpu', 'cuda']\n","for device_option in device_options:\n","    device = torch.device(device_option)\n","    model.to(device)\n","    \n","    print(f\"파라미터 디바이스를 {device_option} 로 변경\")\n","    for weight in model.parameters():\n","        print(f\"파라미터 디바이스: {weight.device}\")\n","    print()"],"id":"pEOar6EWS_AM","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l1ve5Ky2S_AN"},"source":["#### Cautions\n","\n","새로운 텐서를 GPU 에 생성하고 싶은 경우 `torch.randn(2,2).cuda()` 처럼 생성하면\n","\n","1) CPU 메모리에 텐서를 생성 2) CPU -> GPU 메모리로 값을 이동하는 과정이 일어나면서 cost efficient 하지 못합니다\n","\n","`torch.randn(2,2, device=torch.device('cuda:0'))` 와 같이 처음부터 GPU 메모리에 생성하는 것을 권장합니다."],"id":"l1ve5Ky2S_AN"},{"cell_type":"markdown","metadata":{"id":"bq7KXuyfS_AN"},"source":["#### Cautions\n"," - 연산하는 두 개의 텐서는 반드시 같은 device 에 존재하여야 합니다.\n"," - 그렇지 않으면 에러가 발생합니다."],"id":"bq7KXuyfS_AN"},{"cell_type":"code","metadata":{"id":"2LjfibL_S_AN"},"source":["data1 = torch.randn(2,2, device=torch.device('cpu'))\n","data2 = torch.randn(2,2, device=torch.device('cpu'))\n","print(data1 + data2)  # 두 텐서가 같은 device(CPU) 에 있기에 연산이 가능합니다."],"id":"2LjfibL_S_AN","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KpDpGzCqS_AO"},"source":["data1 = torch.randn(2,2, device=torch.device('cpu'))\n","data2 = torch.randn(2,2, device=torch.device('cuda'))\n","print(data1 + data2)  # 두 텐서가 다른 device(CPU, GPU) 에 있기에 연산이 불가능합니다."],"id":"KpDpGzCqS_AO","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wcvHa8G5S_AO"},"source":["### forward\n"," - nn.Module 을 상속한 객체를 직접 호출할 때 수행하는 연산을 정의합니다.\n"," - `model(input)` 을 통해 모델의 예측값을 계산할 수 있습니다.\n"," - Defines the computation performed at every call"],"id":"wcvHa8G5S_AO"},{"cell_type":"code","metadata":{"scrolled":true,"id":"UXQuTb-4S_AO"},"source":["dummy_input = torch.randn(1, 1, 12, 12, device=device)\n","model.to(device)\n","output = model(dummy_input)\n","print(f\"모델 output 사이즈: {output.size()}\")\n","print(output)"],"id":"UXQuTb-4S_AO","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IrbF9fD9S_AP"},"source":["#### Cautions\n"," - 위에서 말씀드린 것과 같은 원리로 모델과 인풋의 device 는 반드시 같아야 합니다."],"id":"IrbF9fD9S_AP"},{"cell_type":"code","metadata":{"id":"o-pjTeVaS_AP"},"source":["cpu_device = torch.device('cpu')\n","gpu_device = torch.device('cuda')\n","\n","# device is same\n","dummy_input = dummy_input.to(gpu_device)\n","model.to(gpu_device)\n","output = model(dummy_input)  # 잘 작동합니다 \n","print(f\"모델 ouput 사이즈: {output.size()}\")"],"id":"o-pjTeVaS_AP","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"aAwqrvnpS_AP"},"source":["dummy_input = dummy_input.to(cpu_device)\n","model.to(gpu_device)\n","\n","# device is different\n","# RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same\n","output = model(dummy_input)  # 에러 발생\n","print(f\"모델 ouput 사이즈: {output.size()}\")"],"id":"aAwqrvnpS_AP","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P8ThIO4jS_AQ"},"source":["### requires_grad()\n"," - autograd 가 해당 모델의 연산을 기록할지를 결정합니다\n"," - false 일 시, 수행하는 연산을 기록하지 않고 따라서 역전파가 되지 않아 학습에서 제외됩니다.\n"," - Change if autograd should record operations on parameters in this module."],"id":"P8ThIO4jS_AQ"},{"cell_type":"code","metadata":{"id":"ixAWEZ3iS_AQ"},"source":["# requires_grad = False\n","model.requires_grad_(requires_grad=False)\n","for param, weight in model.named_parameters():\n","    print(f\"파라미터 {param:15} 가 gradient 를 tracking 하나요? -> {weight.requires_grad}\")"],"id":"ixAWEZ3iS_AQ","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rysdVfBOS_AR"},"source":["# requires_grad = True\n","model.requires_grad_(requires_grad=True)\n","for param, weight in model.named_parameters():\n","    print(f\"파라미터 {param:15} 가 gradient 를 tracking 하나요? -> {weight.requires_grad}\")"],"id":"rysdVfBOS_AR","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4oj9DI74S_AR"},"source":["### train(), eval()\n"," - 모델을 training(evaluation) 모드로 전환합니다.\n"," - training 과 evaluation 이 다르게 작용하는 모듈들(Dropout, BatchNorm) 에 영향을 줍니다.\n"," - 학습 단계에서는 training 모드로, 인퍼런스 단계에서는 eval 모드로 전환해주어야 합니다.\n"," - [아래](https://github.com/pytorch/pytorch/blob/1.6/torch/nn/modules/batchnorm.py#L110-L117)는 BatchNorm2d 의 파이토치 구현입니다. `self.training=True` 일 경우에만, `running_mean`, `running_var` 을 tracking 합니다.\n"," \n","```\n","if self.training and self.track_running_stats:\n","    # TODO: if statement only here to tell the jit to skip emitting this when it is None\n","    if self.num_batches_tracked is not None:\n","        self.num_batches_tracked = self.num_batches_tracked + 1\n","        if self.momentum is None:  # use cumulative moving average\n","            exponential_average_factor = 1.0 / float(self.num_batches_tracked)\n","        else:  # use exponential moving average\n","            exponential_average_factor = self.momentum\n","```"],"id":"4oj9DI74S_AR"},{"cell_type":"code","metadata":{"id":"tCxiUYFmS_AS"},"source":["model.train()  # train mode 로 전환\n","print(f\"model.bn1.training: {model.bn1.training}\")"],"id":"tCxiUYFmS_AS","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NoQ2axpcS_AS"},"source":["model.eval()  # eval mode 로 전환\n","print(f\"model.bn1.training: {model.bn1.training}\")"],"id":"NoQ2axpcS_AS","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jvvl6abnS_AS"},"source":["### 파이토치 공식 문서에서 nn.Module 에 관한 더 많은 정보를 얻을 수 있습니다.\n","https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n","\n","궁금증이 생기면 공식 문서를 참고하는걸 강력 추천합니다."],"id":"Jvvl6abnS_AS"}]}