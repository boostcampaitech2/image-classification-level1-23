{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"3_DataGeneration.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"geographic-foster"},"source":["# Lesson 4 - Data Generation\n","- 이번 실습자료에서는 파이토치 모델에 이미지를 입력값으로 주기위해 전처리를 하는 방법을 배웁니다.\n","- 파이토치는 torch.utils.data에 있는 Dataset, DataLoader 클래스가 이 작업을 간편하게 해줍니다.\n","## 0. Libraries & Configurations\n","- 시각화에 필요한 라이브러리와 데이터 경로를 설정합니다."],"id":"geographic-foster"},{"cell_type":"code","metadata":{"id":"occasional-boxing"},"source":["import os\n","import sys\n","from glob import glob\n","import numpy as np\n","import pandas as pd\n","import cv2\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from tqdm.notebook import tqdm\n","from time import time\n","\n","import torch\n","import torch.utils.data as data\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"id":"occasional-boxing","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"complex-israel"},"source":["### Configurations\n","data_dir = '학습 이미지 폴더의 경로를 입력해주세요.'\n","img_dir = f'{data_dir}/images'\n","df_path = f'{data_dir}/train.csv'"],"id":"complex-israel","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"whole-computer"},"source":["df = pd.read_csv(df_path)\n","df.head()"],"id":"whole-computer","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"minute-neighborhood"},"source":["## 1. Image Statistics"],"id":"minute-neighborhood"},{"cell_type":"markdown","metadata":{"id":"christian-protest"},"source":["- 2강 실습자료에서 사용되었던 데이터셋의 RGB 평균, 표준편차를 구하는 함수를 이용하여 그에 대해 계산합니다."],"id":"christian-protest"},{"cell_type":"code","metadata":{"id":"crude-frank"},"source":["def get_ext(img_dir, img_id):\n","    filename = os.listdir(os.path.join(img_dir, img_id))[0]\n","    ext = os.path.splitext(filename)[-1].lower()\n","    return ext"],"id":"crude-frank","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"superb-profession"},"source":["def get_img_stats(img_dir, img_ids):\n","    img_info = dict(heights=[], widths=[], means=[], stds=[])\n","    for img_id in tqdm(img_ids):\n","        for path in glob(os.path.join(img_dir, img_id, '*')):\n","            img = np.array(Image.open(path))\n","            h, w, _ = img.shape\n","            img_info['heights'].append(h)\n","            img_info['widths'].append(w)\n","            img_info['means'].append(img.mean(axis=(0,1)))\n","            img_info['stds'].append(img.std(axis=(0,1)))\n","    return img_info"],"id":"superb-profession","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"id":"undefined-patrol"},"source":["img_info = get_img_stats(img_dir, df.path.values)\n","\n","print(f'RGB Mean: {np.mean(img_info[\"means\"], axis=0) / 255.}')\n","print(f'RGB Standard Deviation: {np.mean(img_info[\"stds\"], axis=0) / 255.}')"],"id":"undefined-patrol","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"compliant-operation"},"source":["## 2. Dataset\n","- 이 부분에서는 Dataset을 정의하는 방법을 간단하게 배웁니다."],"id":"compliant-operation"},{"cell_type":"markdown","metadata":{"id":"democratic-juvenile"},"source":["## 2.1 Augmentation Function\n","- 3강에서 배운 Augmentation 함수를 정의합니다.\n","- mean, std는 임의로 설정하였으나 파트 1에서 계산한 값을 입력해도 괜찮습니다."],"id":"democratic-juvenile"},{"cell_type":"code","metadata":{"id":"horizontal-strain"},"source":["mean, std = (0.5, 0.5, 0.5), (0.2, 0.2, 0.2)"],"id":"horizontal-strain","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"distant-recycling"},"source":["### 2.1.1 Torchvision Style Augmentation Function\n","- Torchvision에서 제공되는 transforms를 이용한 Augmentation 함수입니다.\n","- 이를 사용하여 Dataset을 정의하여도 괜찮지만, 이번 실습자료에서는 강의에서 배웠던 Albumentation을 활용해봅시다."],"id":"distant-recycling"},{"cell_type":"code","metadata":{"tags":[],"id":"current-hometown"},"source":["''' Torchvision-Style Transforms\n","from torchvision import transforms\n","from torchvision.transforms import Resize, ToTensor, Normalize, GaussianBlur, RandomRotation, ColorJitter\n","\n","\n","class AddGaussianNoise(object):\n","    def __init__(self, mean=0., std=1.):\n","        self.std = std\n","        self.mean = mean\n","\n","    def __call__(self, tensor):\n","        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n","\n","\n","def get_transforms(need=('train', 'val'), img_size=(512, 384)):\n","    transformations = {}\n","    if 'train' in need:\n","        transformations['train'] = transforms.Compose([\n","            Resize((img_size[0], img_size[1])),\n","            RandomRotation([-8, +8]),\n","            GaussianBlur(51, (0.1, 2.0)),\n","            ColorJitter(brightness=0.5, saturation=0.5, hue=0.5),  # todo : param\n","            ToTensor(),\n","            Normalize(mean=mean, std=std),\n","            AddGaussianNoise(0., 1.)\n","        ])\n","    if 'val' in need:\n","        transformations['val'] = transforms.Compose([\n","            Resize((img_size[0], img_size[1])),\n","            ToTensor(),\n","            Normalize(mean=mean, std=std),\n","        ])\n","    return transformations\n","'''"],"id":"current-hometown","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sudden-survivor"},"source":["### 2.1.2 Albumentation Style Augmentation Function\n","- Albumentation은 numpy 형식으로 이미지를 받아 데이터를 변형시킵니다.\n","- opencv 기반으로 빠르고, 다양한 Augmentation 방법이 제공되는 점에서 장점이 있습니다."],"id":"sudden-survivor"},{"cell_type":"code","metadata":{"id":"national-diameter"},"source":["from albumentations import *\n","from albumentations.pytorch import ToTensorV2\n","\n","\n","def get_transforms(need=('train', 'val'), img_size=(512, 384), mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246)):\n","    \"\"\"\n","    train 혹은 validation의 augmentation 함수를 정의합니다. train은 데이터에 많은 변형을 주어야하지만, validation에는 최소한의 전처리만 주어져야합니다.\n","    \n","    Args:\n","        need: 'train', 혹은 'val' 혹은 둘 다에 대한 augmentation 함수를 얻을 건지에 대한 옵션입니다.\n","        img_size: Augmentation 이후 얻을 이미지 사이즈입니다.\n","        mean: 이미지를 Normalize할 때 사용될 RGB 평균값입니다.\n","        std: 이미지를 Normalize할 때 사용될 RGB 표준편차입니다.\n","\n","    Returns:\n","        transformations: Augmentation 함수들이 저장된 dictionary 입니다. transformations['train']은 train 데이터에 대한 augmentation 함수가 있습니다.\n","    \"\"\"\n","    transformations = {}\n","    if 'train' in need:\n","        transformations['train'] = Compose([\n","            Resize(img_size[0], img_size[1], p=1.0),\n","            HorizontalFlip(p=0.5),\n","            ShiftScaleRotate(p=0.5),\n","            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n","            RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n","            GaussNoise(p=0.5),\n","            Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n","            ToTensorV2(p=1.0),\n","        ], p=1.0)\n","    if 'val' in need:\n","        transformations['val'] = Compose([\n","            Resize(img_size[0], img_size[1]),\n","            Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n","            ToTensorV2(p=1.0),\n","        ], p=1.0)\n","    return transformations"],"id":"national-diameter","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"partial-lafayette"},"source":["### 2.2 Define Dataset\n","\n","- 여기에서는 이미지와 레이블을 출력하는 Dataset 클래스를 정의합니다.\n","- 레이블은 마스크 여부, 성별, 나이로 결정이 됩니다.\n","- 레이블은 3(마스크 착용, 미착용, 잘못착용) * 2(남성, 여성) * 3(30세 미만, 30세-60세, 60세 이상) 으로 총 18개가 존재합니다."],"id":"partial-lafayette"},{"cell_type":"code","metadata":{"id":"annoying-emission"},"source":["### 마스크 여부, 성별, 나이를 mapping할 클래스를 생성합니다.\n","\n","class MaskLabels:\n","    mask = 0\n","    incorrect = 1\n","    normal = 2\n","\n","class GenderLabels:\n","    male = 0\n","    female = 1\n","\n","class AgeGroup:\n","    map_label = lambda x: 0 if int(x) < 30 else 1 if int(x) < 60 else 2"],"id":"annoying-emission","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"divine-transmission"},"source":["class MaskBaseDataset(data.Dataset):\n","    num_classes = 3 * 2 * 3\n","\n","    _file_names = {\n","        \"mask1.jpg\": MaskLabels.mask,\n","        \"mask2.jpg\": MaskLabels.mask,\n","        \"mask3.jpg\": MaskLabels.mask,\n","        \"mask4.jpg\": MaskLabels.mask,\n","        \"mask5.jpg\": MaskLabels.mask,\n","        \"incorrect_mask.jpg\": MaskLabels.incorrect,\n","        \"normal.jpg\": MaskLabels.normal\n","    }\n","\n","    image_paths = []\n","    mask_labels = []\n","    gender_labels = []\n","    age_labels = []\n","\n","    def __init__(self, img_dir, transform=None):\n","        \"\"\"\n","        MaskBaseDataset을 initialize 합니다.\n","\n","        Args:\n","            img_dir: 학습 이미지 폴더의 root directory 입니다.\n","            transform: Augmentation을 하는 함수입니다.\n","        \"\"\"\n","        self.img_dir = img_dir\n","        self.mean = mean\n","        self.std = std\n","        self.transform = transform\n","\n","        self.setup()\n","\n","    def set_transform(self, transform):\n","        \"\"\"\n","        transform 함수를 설정하는 함수입니다.\n","        \"\"\"\n","        self.transform = transform\n","        \n","    def setup(self):\n","        \"\"\"\n","        image의 경로와 각 이미지들의 label을 계산하여 저장해두는 함수입니다.\n","        \"\"\"\n","        profiles = os.listdir(self.img_dir)\n","        for profile in profiles:\n","            for file_name, label in self._file_names.items():\n","                img_path = os.path.join(self.img_dir, profile, file_name)  # (resized_data, 000004_male_Asian_54, mask1.jpg)\n","                if os.path.exists(img_path):\n","                    self.image_paths.append(img_path)\n","                    self.mask_labels.append(label)\n","\n","                    id, gender, race, age = profile.split(\"_\")\n","                    gender_label = getattr(GenderLabels, gender)\n","                    age_label = AgeGroup.map_label(age)\n","\n","                    self.gender_labels.append(gender_label)\n","                    self.age_labels.append(age_label)\n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        데이터를 불러오는 함수입니다. \n","        데이터셋 class에 데이터 정보가 저장되어 있고, index를 통해 해당 위치에 있는 데이터 정보를 불러옵니다.\n","        \n","        Args:\n","            index: 불러올 데이터의 인덱스값입니다.\n","        \"\"\"\n","        # 이미지를 불러옵니다.\n","        image_path = self.image_paths[index]\n","        image = Image.open(image_path)\n","        \n","        # 레이블을 불러옵니다.\n","        mask_label = self.mask_labels[index]\n","        gender_label = self.gender_labels[index]\n","        age_label = self.age_labels[index]\n","        multi_class_label = mask_label * 6 + gender_label * 3 + age_label\n","        \n","        # 이미지를 Augmentation 시킵니다.\n","        image_transform = self.transform(image=np.array(image))['image']\n","        return image_transform, multi_class_label\n","\n","    def __len__(self):\n","        return len(self.image_paths)"],"id":"divine-transmission","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"secure-plasma"},"source":["# 정의한 Augmentation 함수와 Dataset 클래스 객체를 생성합니다.\n","transform = get_transforms(mean=mean, std=std)\n","\n","dataset = MaskBaseDataset(\n","    img_dir=img_dir\n",")\n","\n","# train dataset과 validation dataset을 8:2 비율로 나눕니다.\n","n_val = int(len(dataset) * 0.2)\n","n_train = len(dataset) - n_val\n","train_dataset, val_dataset = data.random_split(dataset, [n_train, n_val])\n","\n","# 각 dataset에 augmentation 함수를 설정합니다.\n","train_dataset.dataset.set_transform(transform['train'])\n","val_dataset.dataset.set_transform(transform['val'])"],"id":"secure-plasma","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"regulation-membrane"},"source":["## 3. DataLoader\n","- 정의한 Dataset을 바탕으로 DataLoader을 생성합니다.\n","- Dataset은 이미지 한장을 주는 모듈이라면, DataLoader은 여러 이미지를 batch_size만큼 묶어 전달해줍니다."],"id":"regulation-membrane"},{"cell_type":"code","metadata":{"id":"blessed-robert"},"source":["# training dataloader은 데이터를 섞어주어야 합니다. (shuffle=True)\n","train_loader = data.DataLoader(\n","    train_dataset,\n","    batch_size=12,\n","    num_workers=4,\n","    shuffle=True\n",")\n","\n","val_loader = data.DataLoader(\n","    val_dataset,\n","    batch_size=12,\n","    num_workers=4,\n","    shuffle=False\n",")"],"id":"blessed-robert","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tracked-richardson"},"source":["## 4.  Visualize Processed Data\n","- 파트 4에선 정의한 DataLoader을 이용하여 데이터가 어떻게 전처리 되었는지 시각화하여 확인합니다."],"id":"tracked-richardson"},{"cell_type":"code","metadata":{"id":"explicit-bathroom"},"source":["images, labels = next(iter(train_loader))\n","print(f'images shape: {images.shape}')\n","print(f'labels shape: {labels.shape}')"],"id":"explicit-bathroom","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"several-reynolds"},"source":["from torchvision import transforms\n","\n","# Augmentation으로 이미지를 Normalize했기 때문에, 역으로 다시 Normalize 해주어야합니다.\n","inv_normalize = transforms.Normalize(\n","    mean=[-m / s for m, s in zip(mean, std)],\n","    std=[1 / s for s in std]\n",")\n","\n","n_rows, n_cols = 4, 3\n","\n","fig, axes = plt.subplots(n_rows, n_cols, sharex=True, sharey=True, figsize=(16, 24))\n","for i in range(n_rows*n_cols):\n","    axes[i%n_rows][i//(n_cols+1)].imshow(inv_normalize(images[i]).permute(1, 2, 0))\n","    axes[i%n_rows][i//(n_cols+1)].set_title(f'Label: {labels[i]}', color='r')\n","plt.tight_layout()"],"id":"several-reynolds","execution_count":null,"outputs":[]}]}